# goldengate_model
A simple Matlab script that infers the best fit ZTP distribution from undersampled superinfection data.

Model for superinfection prevalence. To address the concern that limited testing of only two samples per person would underestimate the prevalence of superinfection in this cohort, we developed an ecologically inspired computational model to infer the expected number of strains per individual from population level data. Our model has several assumptions: 1) that there is an even (average) risk of HSV2 acquisition across study participants, 2) that this risk is consistent over time, and 3) that each strain is equally detectable. Because we are interested in the average superinfection prevalence, we do not make any extra assumptions about the study population. It is possible that some members have higher acquisition risk than others, or that some member’s risk changes over time, but across the population the single average risk accounts for this variation. Assumption 3 is conservative. When we allow certain strains to be harder to detect than others in our model, the underestimation of superinfection prevalence is more pronounced. In practice, the model generates a simulated data set where the true average prevalence is known. The true distribution of strains is sampled twice, and those data are compared with the experimental findings. The model that most closely generates the experimental data thus gives the true superinfection prevalence while accounting for the fact that individuals might be incorrectly deemed singly infected even though the true number of strains infecting that individual was greater than one.

Mathematical model implementation. To use the model to infer the true superinfection prevalence, we fit the model to the experimental data. We first generated a population of individuals having n=1 or more strains given the average risk of each strain acquisition. This was accomplished by drawning from a zero-truncated Poisson (ZTP) distribution with a specific average prevalence λ: p(n;λ)=λ^n/[(e^λ-1)n!], n∈[1,2,…]. The probability of each strain was assigned to be equal within an individual, and then each individual was randomly sampled twice to mimic the clinical experiment. The resulting simulated data were organized into the same form as the experimental data and the data-sets were compared to determine the best-fit model. Finding the best-fit model amounted to simulating many possible values of the single parameter λ, and finding the value that minimizes the error with the experimental data. We then used the best-fit parameter to calculate the average number of strains infecting an individual, or the average superinfection prevalence across the population as 〈n〉=λ exp⁡(λ)/(exp⁡(λ)-1). Specifically, we minimized the root mean square error (rms) between the data and the model for many possible λ values, and report the best-fit value.
